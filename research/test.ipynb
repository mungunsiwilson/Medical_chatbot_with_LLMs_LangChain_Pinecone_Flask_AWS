{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "351461a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mungunsi\\Desktop\\Medical_chat_bot\\Medical_chatbot_with_LLMs_LangChain_Pinecone_Flask_AWS\\medibot\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, session\n",
    "from src.helper import download_embeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from dotenv import load_dotenv\n",
    "from src.prompt import *\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.secret_key = os.urandom(24).hex()  # Random secret key for sessions\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dca912c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mungunsi\\Desktop\\Medical_chat_bot\\Medical_chatbot_with_LLMs_LangChain_Pinecone_Flask_AWS\\src\\helper.py:50: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "# Initialize components\n",
    "embeddings = download_embeddings()\n",
    "index_name = \"medicalchatbot\"\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "chat_model = ChatGroq(model=\"llama-3.3-70b-versatile\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8be8ad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ MEMORY STORAGE ============\n",
    "# Dictionary to store memory for each user session\n",
    "session_memories = {}\n",
    "# ========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57e26fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_or_create_memory(session_id):\n",
    "    \"\"\"Get existing memory or create new one for session\"\"\"\n",
    "    if session_id not in session_memories:\n",
    "        session_memories[session_id] = ConversationBufferMemory(\n",
    "            memory_key=\"chat_history\",\n",
    "            return_messages=True\n",
    "        )\n",
    "    return session_memories[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc36a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def index():\n",
    "    # Create unique session ID for each user\n",
    "    if 'session_id' not in session:\n",
    "        session['session_id'] = str(uuid.uuid4())\n",
    "    \n",
    "    # Initialize memory for this session\n",
    "    get_or_create_memory(session['session_id'])\n",
    "    \n",
    "    return render_template('chat.html')\n",
    "\n",
    "@app.route('/get', methods=[\"POST\"])\n",
    "def chat():\n",
    "    try:\n",
    "        # Get session ID\n",
    "        session_id = session.get('session_id')\n",
    "        if not session_id:\n",
    "            return \"Please refresh the page to start a new session.\"\n",
    "        \n",
    "        # Get user message\n",
    "        msg = request.form['msg']\n",
    "        print(f\"\\nüì• User ({session_id[:8]}): {msg}\")\n",
    "        \n",
    "        # Get memory for this session\n",
    "        memory = get_or_create_memory(session_id)\n",
    "        \n",
    "        # ============ MEMORY INTEGRATION ============\n",
    "        # 1. Get conversation history from memory\n",
    "        memory_vars = memory.load_memory_variables({})\n",
    "        chat_history = memory_vars.get(\"chat_history\", [])\n",
    "        \n",
    "        # 2. Create prompt WITH memory\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system_prompt),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),  # Memory goes here\n",
    "                (\"human\", \"{input}\"),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # 3. Create chains\n",
    "        question_answering_chain = create_stuff_documents_chain(chat_model, prompt)\n",
    "        rag_chain = create_retrieval_chain(retriever, question_answering_chain)\n",
    "        \n",
    "        # 4. Prepare input with memory\n",
    "        chain_input = {\n",
    "            \"input\": msg,\n",
    "            \"chat_history\": chat_history  # Pass memory to chain\n",
    "        }\n",
    "        \n",
    "        # 5. Get response\n",
    "        response = rag_chain.invoke(chain_input)\n",
    "        answer = response['answer']\n",
    "        \n",
    "        # 6. Save conversation to memory\n",
    "        memory.save_context({\"input\": msg}, {\"output\": answer})\n",
    "        # =============================================\n",
    "        \n",
    "        print(f\"ü§ñ Bot: {answer[:100]}...\")\n",
    "        print(f\"üß† Memory now has {len(memory.chat_memory.messages)} messages\")\n",
    "        \n",
    "        return answer\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return \"I'm having trouble processing your request.\"\n",
    "\n",
    "@app.route('/clear_memory', methods=['POST'])\n",
    "def clear_memory():\n",
    "    \"\"\"Clear memory for current session\"\"\"\n",
    "    session_id = session.get('session_id')\n",
    "    if session_id and session_id in session_memories:\n",
    "        session_memories[session_id].clear()\n",
    "        return \"Memory cleared!\"\n",
    "    return \"No active session.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8081ad78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://172.20.10.3:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"0.0.0.0\", port=5000, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426e7918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59f07ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315f1f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"GOOD LUCK!\\n\\nMay your training sessions be productive, your endurance be strong, and your skills be sharp. May you stay focused, motivated, and injury-free.\\n\\nRemember to believe in yourself, trust your abilities, and have fun playing the game you love.\\n\\nYou've got this! Go out there and give it your all. I'll be rooting for you from afar.\\n\\nLet me know if you need any more advice or guidance. I'm here to help.\\n\\nGO CRUSH THAT GAME!\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chat(agent, \"Nice! wish me luck!\", thread_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8036613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Wilson!\\n\\nAs a center midfielder, you're the heartbeat of the team, responsible for controlling the tempo of the game, distributing the ball, and creating scoring opportunities. It's a vital position that requires a great deal of energy, vision, and skill.\\n\\nI'm sure you'll be working hard to improve your passing range, your ability to read the game, and your endurance to cover the entire pitch. Remember to stay focused, communicate effectively with your teammates, and always be looking for ways to create space and exploit weaknesses in the opposition's defense.\\n\\nAs a center midfielder, you'll be involved in almost every play, so it's essential to stay hydrated, fueled, and mentally sharp throughout the game. Make sure to take care of yourself, both on and off the pitch, and you'll be ready to put in a top-notch performance.\\n\\nWhat's your favorite team or player, Wilson? Do you have any pre-game rituals or superstitions that help you get ready for a match?\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(agent, \"My name is wilson i play as a center mid\", thread_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8adb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is **Wilson**, and you play as a **Center Midfielder**.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(agent, \"can you remind me of my name and position?\", thread_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
